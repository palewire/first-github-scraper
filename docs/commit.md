<nav>
  <div class="row">
    <div class="sevencol">
      <div class="shingle">
        <a href="https://palewi.re/">
          <div rel="rnews:copyrightedBy rnews:hasSource rnews:providedBy">
            <div about="http://palewi.re/" typeof="rnews:Organization">
              <div property="rnews:name">palewire</div>
            </div>
          </div>
        </a>
      </div>
    </div>
    <div class="fivecol last links">
      <ul>
        <li>
          <a href="http://palewi.re/posts/" title="Posts">
            Posts
          </a>
        </li>
        <li>
          <a href="http://palewi.re/work/" title="Work">
            Work
          </a>
        </li>
        <li>
          <a href="http://palewi.re/talks/" title="Talks">
            Talks
          </a>
        </li>
        <li>
          <a href="http://palewi.re/who-is-ben-welsh/" title="Who is Ben Welsh?">
            About
          </a>
        </li>
      </ul>
    </div>
  </div>
</nav>
<div class="row topbar">
    <div class="twelvecol last"></div>
</div>

# Save the data

* Add a new step to the Action that commits the data file after the scrape. It should continue a bug.
* Open the data file and remove one line of data
* Commit that change and push to GitHub
* Run the scraper manually again from the Action tab
* Watch the job crash
* Point out that you get freebie notification in your email
* Open the job on github and read the error message. Help people diagnose the bug.
* Patch the bug locally.
* Commit and push again.
* Run the scraper manually again.
* Inspect to the data file to see the commit caused by our scraper